{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3129cb-8403-44c7-840d-2bbc6a02e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch                     \n",
    "import torch.nn as nn            \n",
    "import torch.nn.functional as F\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b628c7f-b527-407d-a155-59bf4c5c2747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 6, 5)\n",
    "        self.fc = nn.LazyLinear(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b5f06b-500a-4d6f-858a-81901019b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "[2023-03-18 08:17:43,035] torch._inductor.debug: [WARNING] model__2_forward_7 debug trace: /pytorch-examples/pytorch-graph-optim/torch_compile_debug/run_2023_03_18_08_07_50_087949-pid_825/aot_torchinductor/model__2_forward_7.4\n",
      "[2023-03-18 08:17:43,095] torch._inductor.debug: [WARNING] model__2_backward_8 debug trace: /pytorch-examples/pytorch-graph-optim/torch_compile_debug/run_2023_03_18_08_07_50_087949-pid_825/aot_torchinductor/model__2_backward_8.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing FX graph to file: /pytorch-examples/pytorch-graph-optim/torch_compile_debug/run_2023_03_18_08_07_50_087949-pid_825/aot_torchinductor/model__2_forward_7.4/graph_diagram.svg\n",
      "Writing FX graph to file: /pytorch-examples/pytorch-graph-optim/torch_compile_debug/run_2023_03_18_08_07_50_087949-pid_825/aot_torchinductor/model__2_backward_8.5/graph_diagram.svg\n"
     ]
    }
   ],
   "source": [
    "!rm -rf torch_compile_debug\n",
    "model = SimpleModel().to(device)\n",
    "input_tensor = torch.randn(1,1,32,32).to(device)\n",
    "\n",
    "model(input_tensor)\n",
    "compiled_model = torch.compile(model, backend=\"inductor\", \n",
    "                       options={'trace.graph_diagram':True,\n",
    "                                'trace.enabled':True})\n",
    "\n",
    "\n",
    "out = compiled_model(input_tensor).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485b0e52-f492-4569-8a82-e5207f626b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aten = torch.ops.aten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17bc97a-9081-475d-a1ef-22488814f828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_OpNamespace' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_OpNamespace' object is not callable"
     ]
    }
   ],
   "source": [
    "aten.convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b716bc-1a8b-413c-a7c9-da8e80da8b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "from torch._inductor.ir import ReductionHint\n",
    "from torch._inductor.ir import TileHint\n",
    "from torch._inductor.triton_ops.autotune import pointwise\n",
    "from torch._inductor.utils import instance_descriptor\n",
    "\n",
    "@pointwise(size_hints=[8192], filename='test', meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*i1', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]})\n",
    "@triton.jit\n",
    "def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):\n",
    "    xnumel = 4704\n",
    "    xoffset = tl.program_id(0) * XBLOCK\n",
    "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
    "    xmask = xindex < xnumel\n",
    "    x0 = xindex\n",
    "    x2 = (xindex // 784)\n",
    "    tmp0 = tl.load(in_ptr0 + (x0), xmask)\n",
    "    tmp1 = tl.load(in_ptr1 + ((x0 // 784)), xmask)\n",
    "    tmp4 = tl.load(in_ptr1 + (x2), xmask)\n",
    "    tmp2 = tmp0 + tmp1\n",
    "    tmp3 = tl.where(0 != 0, 0, tl.where(0 > tmp2, 0, tmp2))\n",
    "    tmp5 = tmp0 + tmp4\n",
    "    tmp6 = tl.where(0 != 0, 0, tl.where(0 > tmp5, 0, tmp5))\n",
    "    tmp7 = 0.0\n",
    "    tmp8 = tmp6 <= tmp7\n",
    "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)\n",
    "    tl.store(out_ptr1 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp8, xmask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e7a0fc0-9360-4447-8a64-aa64ea795ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch._inductor.codecache import AsyncCompile\n",
    "async_compile = AsyncCompile()\n",
    "\n",
    "triton__0 = async_compile.triton('''\n",
    "import triton\n",
    "import triton.language as tl\n",
    "from torch._inductor.ir import ReductionHint\n",
    "from torch._inductor.ir import TileHint\n",
    "from torch._inductor.triton_ops.autotune import pointwise\n",
    "from torch._inductor.utils import instance_descriptor\n",
    "\n",
    "@pointwise(size_hints=[8192], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*i1', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]})\n",
    "@triton.jit\n",
    "def triton_(in_ptr0, in_ptr1, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):\n",
    "    xnumel = 4704\n",
    "    xoffset = tl.program_id(0) * XBLOCK\n",
    "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
    "    xmask = xindex < xnumel\n",
    "    x0 = xindex\n",
    "    x2 = (xindex // 784)\n",
    "    tmp0 = tl.load(in_ptr0 + (x0), xmask)\n",
    "    tmp1 = tl.load(in_ptr1 + ((x0 // 784)), xmask)\n",
    "    tmp4 = tl.load(in_ptr1 + (x2), xmask)\n",
    "    \n",
    "    \n",
    "    tmp2 = tmp0 + tmp1\n",
    "    tmp3 = tl.where(0 != 0, 0, tl.where(0 > tmp2, 0, tmp2))\n",
    "    tmp5 = tmp0 + tmp4\n",
    "    tmp6 = tl.where(0 != 0, 0, tl.where(0 > tmp5, 0, tmp5))\n",
    "    tmp7 = 0.0\n",
    "    tmp8 = tmp6 <= tmp7\n",
    "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp3, xmask)\n",
    "    tl.store(out_ptr1 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp8, xmask)\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6401d76f-a3f8-4d61-938e-625f481bed21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TritonFuture' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtriton__0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TritonFuture' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "triton__0.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fc192-0e31-4b13-a6e1-8a57e5226aca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
